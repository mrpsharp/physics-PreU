\documentclass[revision-guide.tex]{subfiles}
%% Current Author: PS
\setcounter{chapter}{15}
\begin{document}
\raggedbottom
\chapter{Molecular Kinetic Theory}
\begin{content}
\item absolute scale of temperature
\item equation of state
\item kinetic theory of gases
\item kinetic energy of a molecule
\item first law of thermodynamics
\item entropy
\item second law of thermodynamics
\end{content}

\subsection*{Candidates should be able to:}

\spec{explain how empirical evidence leads to the gas laws and to the idea of an absolute scale of temperature}

In the seventeenth century Robert Boyle began making quantitative measurements on gases at different pressures. By observing the results of varying the volumes of gases on their pressures he postulated what has become known as Boyles' Law.

\begin{center}
The product of the pressure and volume of a sample of gas at constant termperature remains constant.
\end{center}

Developing a quantitative scale for temperature was a difficult process\footnote{see Hasok Chang's \emph{Inventing Temperature} for more details} and it was not until the end of the eighteenth century that a relationship between pressure and temperature was discovered. Pressure was found to be linearly related to temperature as measured in the celsius scale. It was found that all samples of gases had the same intercept with the x-axis and this lead to the idea of \emph{absolute zero}, the temperature at which the pressure of the gas would be zero.

\begin{figure}[ht]
    \begin{tikzpicture}
        \draw[->](0,0) -- (10,0) node[anchor=north] {$T$ \si{\celsius}};
        \draw[->](8,-0.2) -- (8,5) node[anchor=west] {$P$};
        \draw[thick, red, dashed] (1,0) -- (8,3.0975);
        \draw[thick, red] (8,3.0975) -- (9.7,3.85);
        \draw (8.1,3.175) node[color=blue] {x};
        \draw (8.4,3.25) node[color=blue] {x};
        \draw (8.7,3.4) node[color=blue] {x};
        \draw (9.0,3.5) node[color=blue] {x};
        \draw (9.3,3.65) node[color=blue] {x};
        \draw (9.6,3.75) node[color=blue] {x};
        \draw[->] (1,-1) node[anchor=north]{Absolute Zero} -- (1,-0.2);
    \end{tikzpicture}
    \caption{Pressure against Temperature of a Gas}
\end{figure}

The temperature of Absolute Zero was defined as zero kelvin, \SI{0}{\kelvin} with this being equal to \SI{-273}{\celsius}. This scale is known as the absolute temperature scale.

If the absolute temperature scale is used, then two more empirical laws can be stated. The first is Charles' Law:

\begin{center}
For gas at a fixed pressure, the volume of a sample of gas is proportional to its absolute temperature.
\end{center}

The second is Gay-Lussac's law:

\begin{center}
For a fixed volume of gas, the pressure is proportional to the absolute temperature.
\end{center}

\spec{use the units kelvin and degrees Celsius and convert from one to the other}

Conversion between kevin and degrees celsius is simply a matter of adding or subtracting 273 as the two scale share the same size of unit:
$$ \SI{0}{\kelvin} = \SI{-273}{\celsius}$$

\spec{recognise and use the Avogadro number $N_A = \SI{6.02e23}{\per\mol}$}

The Avogadro number is the number of particles (atoms or molecules) which are present in one mole of the substance. It can also be thought of as the constant of proportionality between the mass of the particle and the mass of one mole of the substance.

For example, using carbon-12:
$$ N = \frac{\SI{0.012}{\kilo\gram}}{\SI{1.99e-26}{\kilo\gram}} = 6.0302\times10^{23}$$

The number of moles of a substance can be found by:
\begin{enumerate}
\item dividing the number of particles by the Avogadro number;
\item dividing the mass of the sample by the molar mass.
\end{enumerate}

\spec{recall and use pV = nRT as the equation of state for an ideal gas}

This equation includes the following quantities:

\begin{center}\begin{tabular}{ccc}
Symbol & Quantity & Standard Unit \\ \hline
$p$ & pressure & \si{\pascal} \\
$V$ & volume & \si{\metre^3} \\
$n$ & no. of moles of the gas & N/A \\
$R$ & the molar gas constant & \si{\joule\per\mole\per\kelvin} \\
$T$ & the absolute temperature & \si{\kelvin} \\
\end{tabular}\end{center}

$R$, the molar gas constant, has a value of \SI{8.314}{\joule\per\mole\per\kelvin} and is equal to $N_A k$.

\spec{describe Brownian motion and explain it in terms of the particle model of matter}

When a small, visible particle such as a pollen grain or smoke particle is observed under a microscope it is seen to move around in an erratic, random manner. This is explained by the fact that it is being constantly bombarded by air molecules whose effects do not quite cancel out. Since the pollen grain or smoke particle is much more massive than the air molecules it follows that these must be moving very rapidly. In 1905 Albert Einstein published a detailed statistical treatment of Brownian motion using the theory of atoms and thus Brownian motion provides very strong evidence for the atomic hypothesis.

\spec{understand that the kinetic theory model is based on the assumptions that the particles occupy no volume, that all collisions are elastic, and that there are no forces between particles until they collide}

Notes on these assumptions:
\begin{enumerate}
  \item \SI{1}{\metre^3} of air contains approximately $$N = \frac{PV}{KT} = \frac{\SI{101}{\kilo\pascal}\SI{1}{\metre^3}}{\SI{1.38e-23}{\joule\per\kelvin}\SI{298}{\kelvin}} = 2.5\times 10^{25}$$
  particles. If these particles are modeled as spheres with a diameter of \SI{300}{\pico\metre} then the particles take up a fraction of the total volume of around $10^{-27}$.
  \item Elastic collisions mean that the kinetic energy of the particles is not lost.
  \item The particles travel in straight lines between collisions. Forces between the particles would cause them to clump together. The lack of forces between particles also means that all the energy is in the form of kinetic energy of the particles.
\end{enumerate}

\spec{understand that a model will begin to break down when the assumptions on which it is based are no longer valid, and explain why this applies to kinetic theory at very high pressures or very high or very low temperatures}

\begin{description}
  \item[High pressures] At high pressures particles will be forces together. This means that the first assumption about negligible volume may break down as the gaps between particles decreases. In addition, the gas may get close to the point of condensation and particles may begin to attract each other.
  \item[Very low temperatures] Similarly to high pressures, at low temperatures the molecules may be very close to one another and may begin to condense, implying forces between particles.
  \item[Very high temperatures] At very high temperatures atoms become a plasma, i.e. separate into positive ions and free electrons. Under such circumstances forces exist between the particles.
\end{description}

\spec{derive $PV=\frac{1}{3}Nm\langle c^2\rangle$ from first principles to illustrate how the microscopic particle model can account for macroscopic observations}

This theory assumes that pressure is caused by the averaging the many elastic collisions of a number of particles with the walls of the container.

\begin{figure}[ht]
    \begin{center}\begin{tikzpicture}
        \draw (0,0) rectangle (10,10);
        \fill (5,5) circle (2pt);
        \draw[->] (5,5) -- (6,6) node[anchor=west] {$v$};
        \draw[->, red] (5,5) -- (6,5) node[anchor=west] {$v_x$};
        \draw[<->] (0.1, 1) -- (9.9,1) node[midway, above] {$d$};
    \end{tikzpicture}\end{center}
    \caption{A particle in a box}
\end{figure}

When the particle, $i$,  collides with the right-hand wall of the box it rebounds with the same y-velocity and a negative x-velocity. The change in momentum of the particle is therefore $ \Delta p = 2mv_x $, where $m$ is the mass of the particle. This is equal to the impulse delivered on the wall during the particle collision.
$$ \text{Impulse} = 2mv_x $$
The particle will now travel to the left-hand side of the box and back. The time taken to do this is equal to $2d/v_x$. We can therefore think of the impulse due to a single collision being averaged over this period of time. If this is the case then the force due to an individual particle is given as:
\[ f_i = \frac{2mv_x}{2d/v_x} = \frac{m{v_x}^2}{d}\]
If we take a system of $N$ particles and replace the properties of our particle with the average properties of the particles in the system we get:
\[ F = \sum_i f_i = \frac{Nm\langle{v_x}^2\rangle}{d}\]
Note that this includes the expression $\langle{v_x}^2\rangle$ - the mean of the squared x-velocity. The order here is important and the mean velocity of the particles is zero. The square of a component of velocity is related to the velocity by pythagoras:
\[ c^2 = {v_x}^2 + {v_y}^2 + {v_z}^2\]
Now we are using many particles we can make the assumption that a particle is equally likely to be travelling in any direction, therefore
\[ \langle{v_x}^2\rangle = \langle{v_y}^2\rangle = \langle{v_z}^2\rangle \]
giving
\[ \langle{v_x}^2\rangle = \frac{1}{3}\langle c^2 \rangle \]
Substitution into the equation for $F$ gives
\[ F = \frac{\frac{1}{3}Nm\langle c^2\rangle}{d} \]
and
\[ P = \frac{F}{A} = \frac{\frac{1}{3}Nm\langle c^2\rangle}{Ad} \]
We now note that $Ad$ is equal to the volume of the box and re-arrange to give
\[ PV = \frac{1}{3}Nm\langle c^2\rangle \]



\spec{recognise and use $\frac{1}{2}m\langle c^2\rangle = \frac{3}{2}kT$}

The formula for $PV$ derived above can be equated with the formula from the empirical gas laws ($PV=nRT$) to give:
\[  \frac{1}{3}Nm\langle c^2\rangle = nRT \]
Since $n = N / N_A $ and $ R = N_A k $ the right-hand side becomes $NkT$. This is usually re-arranged to give
\[ \frac{1}{2}m\langle c^2 \rangle = \frac{3}{2}kT \]
as now the left-hand side represents the average kinetic energy of a molecule in the gas. Since this is an ideal gas and has no potential energies this is also the total energy per molecule. Hence the link between the macroscopic quantity of temperature and the microscopic energy per molecule is arrived at.

\spec{understand and calculate the root mean square speed for particles in a gas}

The root mean square (RMS) is usually calculated by re-arranging the equation above and square-rooting:

$$ \sqrt{\langle c^2 \rangle} = \sqrt{\frac{3kT}{m}} $$

\spec{understand the concept of internal energy as the sum of potential and kinetic energies of the molecules}

In an ideal gas the internal energy is equal to the sum of kinetic energies of the molecules, i.e.

$$ U = \frac{1}{2}Nm\langle c^2 \rangle = \frac{3}{2}NkT $$

\spec{recall and use the first law of thermodynamics expressed in terms of the change in internal energy, the heating of the system and the work done on the system}

This can be written as:
$$ \Delta U = \Delta Q + \Delta W $$
\emph{Note that in some textbooks the first law is written in terms of the work done \emph{by} the system, giving $\Delta W$ a different sign. If you think in terms of conservation of energy in the particular example you will be alright.}

\begin{figure}[h]
  \begin{tikzpicture}[domain=1:9]
    \draw[->] (-0.5,0) -- (12,0) node[anchor=north] {$V$};
    \draw[->] (0,-0.5) -- (0,10) node[anchor=east] {$P$};
    \draw (1,9) node[anchor=south]  {\textbf{A}};
    \draw[thick, ->]  (1,9) .. controls (4,7) and (7,6.2) .. (8,6) node[midway, anchor=south west] {\textbf{1}};
    \draw[thick, ->] (8,6) .. controls (9,4.5) and (10,3) .. (12,1) node[anchor=south west, midway] {\textbf{2}};
    \draw[thick, ->] (12,1) .. controls (8,1.5)  .. (3,3) node[midway, anchor=north east] {\textbf{3}};
    \draw[thick, ->] (3,3) .. controls (1.6,6)  .. (1,9) node[midway, anchor=north east] {\textbf{4}};
  \end{tikzpicture}
  \caption{The Carnot Cycle}
  \label{carnotcycle}
\end{figure}

The Carnot Cycle shown in Firgure \ref{carnotcycle} is commonly used to test the understanding for the first law. The cycle begins and ends at point \textbf{A}. This means that the internal energy of the system at the start and end of the cycle is the same (as $PV=nRT$ and $T$ is proportional to the internal energy). The changes at each stage of the cycle are as follows:

\begin{description}
  \item[1. Isothermal Expansion] In stage 1 the gas expands at contant temperature. Since it is expanding, the gas is doing work on the surroundings and since it is at constant temperature the internal energy of the gas remains constant. Therefore the second law implies that the gas must be absorbing heat. \emph{Note that isothermal changes are often indicated by describing the change as occuring slowly.}
  \item[2. Adiabatic Expansion] In stage 2 the gas expands without transferring heat to/from the surroundings. Since it is doing work the gas's internal energy drops, as does its temperature.
  \item[3. Isothermal Compression] In stage 3 the gas is compressed at constant temperature. Since work is done on the gas and the internal energy remains constant it must be the case that heat is lost to the surroundings.
  \item[4. Adiabatic Compression] Finally, the gas is compressed without heat transfer to/from the surroundings. Work is done on the gas and therefore the internal energy, and temperature, increase.
\end{description}


\begin{example}

Complete the table for the Carnot Cycle shown in figure \ref{carnotcycle}.

\begin{tabular}{|c|p{3cm}|p{3cm}|p{3cm}|}
  \hline
  stage & \centering thermal energy supplied \textbf{to} the gas / J & \centering work done \textbf{on} the gas / J & \centering \textbf{increase} in internal energy of the gas / J \tabularnewline \hline
  1 & \centering\centering(a) & \centering-936 & \centering(b) \tabularnewline \hline
  2 & \centering0 & \centering(c) & \centering(d) \tabularnewline \hline
  3 & \centering(e) & \centering+702 & \centering0 \tabularnewline \hline
  4 & \centering(f) & \centering+844 & \centering+844 \tabularnewline \hline
\end{tabular}


\answer

In stage 1 there is no change in internal energy of the gas, so (b) equals zero. In order to satisfy the first law of thermodynamics the thermal energy supplied must equal the work done \textbf{by} the gas so (a) equals \SI{+936}{\joule}.

As the total change in internal energy throughout the cycle must be zero, we can now calculate (d) as being \SI{-844}{\joule}.

(c) can be calculated using the first law as \SI{-844}{\joule}.

A similar argument to that used in stage 1 can be used in stage 3 to give (e) as \SI{-702}{\joule}.

In stage 4 no energy is transferred by heating therefore (f) is equal to zero.



The final table is therefore:

\begin{tabular}{|c|p{3cm}|p{3cm}|p{3cm}|}
  \hline
  stage & \centering thermal energy supplied \textbf{to} the gas / J & \centering work done \textbf{on} the gas / J & \centering \textbf{increase} in internal energy of the gas / J \tabularnewline \hline
  1 & \centering\centering \textbf{+936} & \centering-936 & \centering \textbf{0} \tabularnewline \hline
  2 & \centering0 & \centering \textbf{-844} & \centering \textbf{-844} \tabularnewline \hline
  3 & \centering \textbf{-702} & \centering+702 & \centering0 \tabularnewline \hline
  4 & \centering \textbf{0} & \centering+844 & \centering+844 \tabularnewline \hline
\end{tabular}

\end{example}


\spec{recognise and use W = p∆V for the work done on or by a gas}

This follows from the definition of work done. If the cross-sectional area is a contant $A$, then derivation is as follows:
\[ W = F\Delta s = PA \times \Delta s = P\Delta V \]

\spec{understand qualitatively how the random distribution of energies leads to the Boltzmann factor $e^{-\frac{E}{kT}}$ as a
measure of the chance of a high energy}

When a large number of particles share a fixed amount of energy between them and are able to transfer energy through random collisions, it turns out that the most likely distribution of energies  follows a specific distribution - the Boltzmann distribution. One of the features of this distribution is that the fraction of particles with an energy greater than a certain amount of energy, $E$, is given by the Boltzmann factor, i.e.
\[ \frac{N_{E}}{N_{total}} = e^{-\frac{E}{kT}} \]
\spec{apply the Boltzmann factor to activation processes including rate of reaction, current in a semiconductor
and creep in a polymer}

From the point above, it follows that the rate of any process which depends on an activation energy is likely to be proportional to the Boltzmann factor.

\begin{center}
  \begin{tabular}{p{3cm}p{4cm}p{4cm}}
    \textbf{Process} & \textbf{Depends on } & \textbf{Energy $E$ represents} \\ \hline \hline
    rate of reaction & the number of particles with an energy above the activation energy & the activation energy of the process \\ \hline
    current in a semiconductor & the number of free charge carriers & the energy required for a charge carrier to move the the conduction band, i.e. the band gap \\ \hline
    creep in a polymer & the ability of the polymer chains to break the weak intermolecular forces between them & the energy required to break the intermolecular bonds between polymer chains \\ \hline
  \end{tabular}
\end{center}

\spec{*describe entropy qualitatively in terms of the dispersal of energy or particles and realise that entropy is related to the number of ways in which a particular macroscopic state can be realised}

A common way of describing the concept of entropy is to focus on the idea of disorder. When discussing entropy scientifically it is important to be precise about what this means. A more precise way of characterising entropy is to think about the number of ways in which a macroscopic state can be realised. For example, imagine seven particles in a quantised system with four units of energy to share between them. Each state can be denoted using the notation $S = \{N_0,N_1,N_2,\ldots\}$ where $N_0$ is the number of particles with this much energy.

For example, one particle could have all four units of energy and the rest have zero. This would be denoted $\{6,0,0,0,1\}$. There are seven different ways in which this macrostate could come about. The total number of microstates can be calculated by the stars and bars method to be $^{11}C_4=210$. The table below shows the different possible macrostates and the number of ways these could be attained.

\begin{table}[h]
\begin{center}
  \begin{tabular}{c|c}
    \textbf{State} & \textbf{No. of microstates} \\ \hline
    $\{6,0,0,0,1\}$ & $ 7$ \\
	$\{5,0,2,0,0\}$ & $^7C_2=21$\\
    $\{5,1,0,1,0\}$ &  $7 \times 6 = 42$ \\
    $\{4,2,1,0,0\}$ & $ ^7C_2\times ^5C_1 = 105$ \\
    $\{3,4,0,0,0\}$ & $^7C_4=35$
  \end{tabular}
\end{center}
  \caption{Macrostates and microstates}
  \label{tbl:macro}
\end{table}

As you can see, there are far more ways to achieve the macrostate $\{4,2,1\}$ than the others. This makes it the state with the highest entropy.

\spec{*recall that the second law of thermodynamics states that the entropy of an isolated system cannot decrease and appreciate that this is related to probability}

If the energy available to a system, or a distribution of particles, is dispersed through random process then over time the most probable configuration will dominate. As the highest entropy macrostate is also the most probable one it is highly likely that the entropy will increase with time.

As an example, consider 100 coins which are all heads-up. There is only one way to arrange for this particular macrostate to occur. There are \num{1.27e30} possible microstates available and therefore if the coins are tossed it is overwhelmingly likely that the disorder in the system is going to increase. If this idea is multiplied up to the billions of particles in even the smallest sample of matter it is seen that all systems will move towards their highest entropy state.

The only way to return to the original state of the coins would be to intervene and sort them individually one-by-one, thus breaking the isolation of the system.

\spec{*understand that the second law provides a thermodynamic arrow of time that distinguishes the future (higher entropy) from the past (lower entropy)}

The idea here is that nature tends towards higher entropy states. For example, consider the two distributions of gas particles in figure \ref{fig:gas-distrib}. In this case it is overwhelmingly likely that \textbf{B} occured after \textbf{A}. Thus, the second law of theormodynamics provides an arrow of time despite the fact that individual particles may be governed by Newton's laws of motion which are fully reversible and do not give any information about the direction of time.

\begin{figure}[ht]
  \begin{center}\begin{tikzpicture}
    \draw (0,0) rectangle (4,4);
    \draw (5,0) rectangle (9,4);
    \foreach \x in {0.25,.5,.75,1} {
      \foreach \y in {.25,.5}
        \fill[color=blue] (\x,\y) circle (1mm);
    }
    \foreach \n in {1,2,...,8} {
      \fill[color=blue] (rnd*3.5+5.25,rnd*3.5+.25) circle (1mm);
    }
    \draw (2,-.5) node {\textbf{A}};
    \draw (7,-.5) node {\textbf{B}};
  \end{tikzpicture}\end{center}
  \caption{Two distributions of particles}
  \label{fig:gas-distrib}
\end{figure}

\spec{*understand that systems in which entropy decreases (e.g. humans) are not isolated and that when their interactions with the environment are taken into account their net effect is to increase the entropy of the Universe}

Living organisms including humans take in relatively simple molecules and create highly complex, ordered structures from them. This appears to violate the second law of thermodynamics and entropy appears to be decreasing. However, an individual \emph{part} of a system can have a net decrease in entropy if it is not isolated. In such a scenario the overall entropy of the universe (the ultimate isolated system) must still increase. In the case of life on earth, the whole biosphere can be seen as a complex heat engine extracting work from the heat energy input from the sun whilst radiating heat into the coldness of space.

\spec{*understand that the second law implies that the Universe started in a state of low entropy and that some physicists think that this implies it was in a state of extremely low probability.}

If the universe is seen as the ultimate isolated system then it follows that the second law of thermodynamics should apply. In this case the universe must be moving from a low entropy state to a high entropy. In isolated systems, low entropy states are also highly improbably and this leads to the idea that our universe's initial state is a highly improbable one. However, this requires us to accept that we can extend the idea of probability to the initial state of the universe and that we are not committing a `category error' by considering the universe as a thermodynamic system in this way.

\end{document}
